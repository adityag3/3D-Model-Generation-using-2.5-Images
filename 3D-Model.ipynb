{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "n2g_2DqZYJ31",
    "outputId": "ea0f8d6f-635a-4704-80a9-78eaa0d535c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlbdhVA4cD-W"
   },
   "outputs": [],
   "source": [
    "datapath =  'drive/My Drive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58VSDxI_kvZ0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv1D, Conv3D, Conv2DTranspose, Conv3DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import keras\n",
    "import os\n",
    "from keras.losses import mean_squared_error, kullback_leibler_divergence\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import binvox_rw\n",
    "from shutil import copyfile\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLWWbgaN-upK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0gQIFgko-u9t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NugQjO8J-sMj"
   },
   "source": [
    "DATA PRE PROCESSING\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WW1bdxFN-wBy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[]] y: [[]]\n",
      "x shape: (1499, 64, 64, 64)\n",
      "y shape: (1499, 320, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def gen_images():\n",
    "    directory = \"species2\"\n",
    "    out_dir = \"./mask_images/\"\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Hardcoding these to avoid mishaps if script runs again by mistake\n",
    "            if filename == \"1.png\": \n",
    "                try:\n",
    "                    print(\"root:\",root,\"dirs:\",dirs,\"files:\",files)\n",
    "                    normal = root+'\\\\1_crop.png'\n",
    "                    #print(\"normal_image path:\"+normal)\n",
    "                    img1 = cv2.imread(root+'/1_crop.png')\n",
    "                    img2 = cv2.imread(root+'/2_crop.png')\n",
    "                    mask = cv2.imread(root+'/3_crop.png',0)\n",
    "                    res2 = cv2.bitwise_or(img1,img2,mask = mask)\n",
    "                    names = root.split(\"\\\\\")\n",
    "                    image_path = out_dir+names[0]+\"_\"+names[1]+\"_\"+names[2]+\"_mask.png\"\n",
    "    #                 print(\"image path:\",image_path)\n",
    "                    cv2.imwrite(image_path,res2)\n",
    "    #             image_name = root+\"_mask.png\"\n",
    "    #             cv2.imwrite('or.png',res2)\n",
    "                except:\n",
    "                    continue        \n",
    "        \n",
    "\n",
    "\n",
    "def gather_binvox():\n",
    "    directory = \"Generated_Foraminifera\"\n",
    "    out_dir = \"./binvox_files/\"\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "           \n",
    "            if filename.endswith(\".binvox\"): \n",
    "                try:\n",
    "                    print(\"root:\",root,\"dirs:\",dirs,\"files:\",files)\n",
    "                    binvox_path = root+\"\\\\\"+filename\n",
    "                    print(\"binvox path:\",binvox_path)\n",
    "                    names = root.split(\"\\\\\")\n",
    "                    print(\"names:\",names)\n",
    "                    out_path = out_dir+names[0]+\"_\"+names[1]+\"_\"+filename\n",
    "                    print(\"out_path:\",out_path)\n",
    "                    copyfile(binvox_path, out_path)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "def map_png_to_binvox(filename):\n",
    "    parts = filename.split(\"_\")\n",
    "    s = parts[0]\n",
    "    num = s[-1]\n",
    "    s2 = s[:-1]\n",
    "    binvox_filename = \"Generated_Foraminifera_\"+s2+\"_\"+num+\"_\"+parts[1]+\"_\"+parts[2]+\".binvox\"\n",
    "    return(binvox_filename)\n",
    "    \n",
    "def images_to_numpy_array():\n",
    "    mask_directory = \"mask_images\"\n",
    "    binvox_directory = \"binvox_files\"\n",
    "    x = [[]] # 3d images\n",
    "    y = [[]] # 2.5 D images\n",
    "    print(\"x:\",x,\"y:\",y)\n",
    "    for root, dirs, files in os.walk(mask_directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".png\"): \n",
    "                yi = cv2.imread(root+\"//\"+filename)\n",
    "                y.append(yi)\n",
    "                binvox_filename = map_png_to_binvox(filename)\n",
    "                with open(binvox_directory+\"//\"+binvox_filename, 'rb') as f:\n",
    "                    model = binvox_rw.read_as_3d_array(f)\n",
    "                    #print(\"model:\",model,\"dim:\",model.dims,\"scale:\",model.scale,\"data:\",model.data)\n",
    "                    num_array = model.data.astype(int)\n",
    "                    #print(\"num array:\",num_array)\n",
    "                    x.append(num_array)\n",
    "                    \n",
    "#     for root, dirs, files in os.walk(binvox_directory):\n",
    "#         for filename in files:\n",
    "#             if filename.endswith(\".binvox\"): \n",
    "#                 with open(root+\"//\"+filename, 'rb') as f:\n",
    "#                     print(\"filename:\",root+\"/\"+filename)\n",
    "#                     model = binvox_rw.read_as_3d_array(f)\n",
    "#                     #print(\"model:\",model,\"dim:\",model.dims,\"scale:\",model.scale,\"data:\",model.data)\n",
    "#                     num_array = model.data.astype(int)\n",
    "#                     #print(\"num array:\",num_array)\n",
    "#                     x.append(num_array)\n",
    "                    \n",
    "    \n",
    "    x.pop(0)\n",
    "    y.pop(0)\n",
    "    \n",
    "    np_arr_y = np.array(y)\n",
    "    np_arr_x = np.array(x)\n",
    "    print(\"x shape:\",np_arr_x.shape)\n",
    "    print(\"y shape:\",np_arr_y.shape)\n",
    "#     print(\"fist y:\",y[0])\n",
    "#     print(\"sec y:\",y[1])\n",
    "    return np_arr_x, np_arr_y\n",
    "\n",
    "    \n",
    "data_X, data_Y = images_to_numpy_array()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "colab_type": "code",
    "id": "RVXO-Bt9kvZ6",
    "outputId": "96db688a-3fa3-498d-ea0c-186df77f62a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1, 1, 1, 200)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv3d_transpose_6: expected ndim=5, found ndim=6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-4a7832c763b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mGM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-79-4a7832c763b1>\u001b[0m in \u001b[0;36mbuild_generator\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv3DTranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    163\u001b[0m                     \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer conv3d_transpose_6: expected ndim=5, found ndim=6"
     ]
    }
   ],
   "source": [
    "# model = encoder()\n",
    "# model.compile(loss=keras.losses.kullback_leibler_divergence,\n",
    "#               optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "#               metrics=['accuracy'])\n",
    "# print(model.summary())\n",
    "\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test),\n",
    "#           callbacks=[history])\n",
    "batch_size = 20\n",
    "noise = np.random.normal(0,1,size=[batch_size, 200])\n",
    "noise = np.reshape(noise,(20, 1,1,1,-1))\n",
    "print(noise.shape)\n",
    "    \n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3DTranspose(512, kernel_size=(4,4,4), strides=(1,1,1),input_shape=(1,1,1,200)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv3DTranspose(256,kernel_size=(4,4,4), strides=(2,2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv3DTranspose(128, kernel_size=(4,4,4),strides=(2,2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv3DTranspose(64, kernel_size=(4,4,4), strides=(2,2,2),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv3DTranspose(1, kernel_size=(4,4,4), strides=(2,2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "GM = build_generator()\n",
    "print(GM.summary())   \n",
    "pred = GM.predict(noise)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91uQAN-tlBsa"
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPLew5EflAmf"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 823
    },
    "colab_type": "code",
    "id": "9cTQWgFgkvZ9",
    "outputId": "78726794-1b12-4293-960e-b6c22358c76a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 320, 320, 3)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 320, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 64, 64)   23296       encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 64, 64, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 64, 64, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 128)  204928      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32, 32, 128)  512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 128)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 256)  819456      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 256)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 512)    3277312     activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 512)    2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 1, 1, 400)    13107600    activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1, 1, 400)    1600        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1, 1, 400)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 1, 200)    80200       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1, 1, 200)    80200       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 200)          0           dense_11[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 17,598,432\n",
      "Trainable params: 17,595,712\n",
      "Non-trainable params: 2,720\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "noise = np.random.normal(0,1,size=[batch_size, 307200])\n",
    "noise = np.reshape(noise,(20, 320,320,3))\n",
    "print(noise.shape)\n",
    "\n",
    "def encoder():\n",
    "    input_shape=(320,320,3)\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    x = Conv2D(64, kernel_size=(11, 11), strides=(5, 5), padding ='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x= Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding ='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x= Conv2D(256, kernel_size=(5, 5), strides=(2, 2), padding ='same')(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x= Activation('relu')(x)\n",
    "    \n",
    "    x=Conv2D(512, kernel_size=(5, 5), strides=(2, 2), padding ='same')(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    \n",
    "    x=Conv2D(400, kernel_size=(8, 8), strides=(1, 1))(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    \n",
    "    z_mean = Dense(200)(x)\n",
    "    z_log_var = Dense(200)(x)\n",
    "    \n",
    "    z = Lambda(sampling, output_shape=(200,), name='z')([z_mean, z_log_var])\n",
    "    model = Model(inputs, z, name='encoder')\n",
    "    return model\n",
    "\n",
    "EM = encoder()\n",
    "print(EM.summary())\n",
    "  \n",
    "pred = EM.predict(noise)\n",
    "#print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "id": "42pQWCqvkvaD",
    "outputId": "3e75c0fb-474d-4da4-ca8f-58629e7d8781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 64, 64, 64, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_6 (Conv3D)            (None, 32, 32, 32, 64)    4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 32, 32, 32, 64)    256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 32, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 16, 16, 16, 128)   524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 16, 16, 16, 128)   512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 16, 16, 16, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 8, 8, 8, 256)      2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 8, 8, 8, 256)      1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 8, 8, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 4, 4, 4, 512)      8389120   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 4, 4, 4, 512)      2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 4, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 1, 1, 1, 1)        32769     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 1, 1, 1, 1)        4         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 1, 1, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1, 1, 1, 1)        0         \n",
      "=================================================================\n",
      "Total params: 11,051,717\n",
      "Trainable params: 11,049,795\n",
      "Non-trainable params: 1,922\n",
      "_________________________________________________________________\n",
      "None\n",
      "(20, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "noise = np.random.normal(0,1,size=[batch_size, 262144])\n",
    "noise = np.reshape(noise,(20,64,64,64,1))\n",
    "print(noise.shape)\n",
    "    \n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(64, kernel_size=(4,4,4), strides=(2,2,2),input_shape=(64, 64, 64,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv3D(128,kernel_size=(4,4,4), strides=(2,2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv3D(256, kernel_size=(4,4,4),strides=(2,2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv3D(512, kernel_size=(4,4,4), strides=(2,2,2),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv3D(1, kernel_size=(4,4,4), strides=(1,1,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "DM = build_discriminator()\n",
    "print(DM.summary())   \n",
    "pred = DM.predict(noise)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "aKHsM2GykvaH",
    "outputId": "2dca36d0-2833-4147-8036-5faba5caf345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Model)              (None, 200)               17598432  \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1, 200)      0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 64, 64, 64, 1)     17572549  \n",
      "_________________________________________________________________\n",
      "sequential_7 (Sequential)    (None, 1, 1, 1, 1)        11051717  \n",
      "=================================================================\n",
      "Total params: 46,222,698\n",
      "Trainable params: 46,216,134\n",
      "Non-trainable params: 6,564\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EDGModel = Sequential()\n",
    "EDGModel.add(EM)\n",
    "EDGModel.add(Reshape((1,1,1,200)))\n",
    "EDGModel.add(GM)\n",
    "EDGModel.add(DM)\n",
    "EDGModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "FNyL50PkkvaJ",
    "outputId": "73046576-bac9-4573-ac0f-778403f68da2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 64, 64, 64, 1)     17572549  \n",
      "_________________________________________________________________\n",
      "sequential_7 (Sequential)    (None, 1, 1, 1, 1)        11051717  \n",
      "=================================================================\n",
      "Total params: 28,624,266\n",
      "Trainable params: 28,620,422\n",
      "Non-trainable params: 3,844\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AMModel = Sequential()\n",
    "AMModel.add(GM)\n",
    "AMModel.add(DM)\n",
    "AMModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqoRgflQ3dql"
   },
   "outputs": [],
   "source": [
    "def KL_loss(self, mu, log_var):\n",
    "        return -0.5 * K.sum(1 + log_var - tf.pow(mu, 2) - tf.exp(log_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eW8AyF0O3-Pj"
   },
   "outputs": [],
   "source": [
    "def sample_z(self, mu, log_var):\n",
    "        eps = K.random_normal(shape=K.shape(mu))\n",
    "        return mu + K.exp(log_var / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqmyeuob4nRX"
   },
   "outputs": [],
   "source": [
    "def NLLNormal(self, pred, target):\n",
    "\n",
    "        c = -0.5 * K.log(2 * np.pi)\n",
    "        multiplier = 1.0 / (2.0 * 1)\n",
    "        tmp = K.square(pred - target)\n",
    "        tmp *= -multiplier\n",
    "        tmp += c\n",
    "\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1499, 64, 64, 64)\n",
      "(1499, 320, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data_X.shape)\n",
    "print(data_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 64, 64, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X[0:20].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIebBd9BkvaN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 80000 values, but the requested shape has 4000\n\t [[{{node reshape_25/Reshape}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-f995139639fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m#         AMModel.train_on_batch([real_2d_images, noise],[real_3d_images,y_noise])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-78-f995139639fb>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;31m#             print(\"Loos on real images of DM\", d_output_x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# STEP 2: Update the encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mEGModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_2d_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_3d_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;31m#         # STEP 3: Update the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 80000 values, but the requested shape has 4000\n\t [[{{node reshape_25/Reshape}}]]"
     ]
    }
   ],
   "source": [
    "# def custom_loss(encoder_output):\n",
    "#   def loss(y_true, y_pred):\n",
    "#     noise = np.random.normal(0,1,size=[batch_size, 200])\n",
    "        \n",
    "#     #200 is the channel size since we have 200 as the number of features.\n",
    "#     noise = np.reshape(noise,(batch_size,1,1,1,200))\n",
    "#     loss1 = kullback_leibler_divergence(noise, encoder_output)\n",
    "#     loss2 = mean_squared_error(y_true, y_pred)\n",
    "#     return loss1+loss2\n",
    "#   return loss\n",
    "\n",
    "def noise_loss(ytrue, ypred):\n",
    "  return log(1-ypred)\n",
    "  \n",
    "def real_loss(ytrue, ypred):\n",
    "  return mean_squared_error(ytrue, ypred)\n",
    "\n",
    "#Compile GM model to train discriminator\n",
    "GM.compile(loss= 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "DM.compile(loss= 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#EDGModel.compile(loss=\"kullback_leibler_divergence\", optimizer='adam', metrics=['accuracy'])\n",
    "#AM.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Compile EG model to train encoder\n",
    "input_shape2=(320,320,3)\n",
    "EGModel = Sequential()\n",
    "EGModel.add(EM)\n",
    "EGModel.add(Reshape((1,1,1,200)))\n",
    "output1 = EGModel.add(GM)\n",
    "EGModel.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# #compile AM model to train generator.\n",
    "# input_shape2=(320,320,3)\n",
    "# input_shape3=(1,1,1,200)\n",
    "# input1 = Input(shape=input_shape2)\n",
    "# input2 = Input(shape=input_shape3)\n",
    "# #Part taking real input in\n",
    "# output1 = EM(input1)\n",
    "# print(output1.shape)\n",
    "# output1 = np.reshape(np.array(output1),(20,1,1,1,200))\n",
    "# output2 = GM()(output1)\n",
    "# #Part which takes noise in\n",
    "# output3 = GM(input2)\n",
    "# output4 = DM()(output3)\n",
    "# losses = [real_loss, noise_loss]\n",
    "# AModel = Model(input =[input1, input2], output=[output2, output4])\n",
    "# AMmodel.compile(optimizer='adam', loss=losses, metrics=[\"accuracy\"])\n",
    "\n",
    "def train_model():\n",
    "    batch_size = 20\n",
    "    \n",
    "    real_2d_images = data_Y\n",
    "    real_2d_images = real_2d_images[:-19]\n",
    "    real_3d_images = data_X\n",
    "    real_3d_images = real_3d_images[:-19]\n",
    "    for i in range(1):\n",
    "        \n",
    "        start = 0\n",
    "        print(len(real_2d_images))\n",
    "        for j in range(len(real_2d_images)//batch_size - batch_size):\n",
    "#             noise = np.random.normal(0,1,size=[batch_size, 200])\n",
    "\n",
    "#             #200 is the channel size since we have 200 as the number of features.\n",
    "#             noise = np.reshape(noise,(batch_size,1,1,1,200))\n",
    "\n",
    "#             # Expect 20 64*64*64 images.\n",
    "#             fake_models = GM.predict(noise)\n",
    "#             print(\"fake\", fake_models.shape)\n",
    "\n",
    "#             noise2 = np.zeros([20, 320,320,3])\n",
    "#             print(noise2.shape)\n",
    "#             a = EM.predict(noise2)\n",
    "#             print(real_3d_images.shape)\n",
    "\n",
    "            real_2d_images = np.reshape(real_2d_images[start:start+batch_size], (batch_size, 320, 320, 3))\n",
    "            real_3d_images = np.reshape(real_3d_images[start:start+batch_size], (batch_size, 64, 64, 64, 1))\n",
    "#             # STEP 1: Update the discriminator\n",
    "#             #x = concatenate 20 real models and 20 fake models\n",
    "#             #y = 1 for the real models and 0 for the fake models\n",
    "#             y_noise = np.zeros([batch_size])  \n",
    "\n",
    "#             y_noise = np.reshape(y_noise,(batch_size,1,1,1,1))\n",
    "#             print(y_noise.shape)\n",
    "#             d_output_z = DM.train_on_batch(fake_models, y_noise)\n",
    "#             print(\"Loss on noise ofDM\", d_output_z)\n",
    "#             y_real = np.ones([batch_size])        \n",
    "#             y_real = np.reshape(y_real,(batch_size,1,1,1,1))\n",
    "#             d_output_x = DM.train_on_batch(real_3d_images, y_real)  \n",
    "#             print(\"Loos on real images of DM\", d_output_x)\n",
    "            # STEP 2: Update the encoder\n",
    "            EGModel.train_on_batch(real_2d_images, real_3d_images)\n",
    "            start = start+batch_size\n",
    "#         # STEP 3: Update the generator\n",
    "#         # now trianing with 1 for noise.\n",
    "#         y_noise = np.ones([batch_size, 1])  \n",
    "#         AMModel.train_on_batch([real_2d_images, noise],[real_3d_images,y_noise])\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phRpi5AUYI1O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
